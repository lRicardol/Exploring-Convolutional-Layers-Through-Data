{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d58aacf",
   "metadata": {},
   "source": [
    "# Exploring Convolutional Layers Through Data and Experiments\n",
    "## Fashion-MNIST Case Study\n",
    "\n",
    "### Context and Motivation\n",
    "In this project, neural networks are treated as architectural components rather than black boxes.\n",
    "The goal is to understand how convolutional layers introduce inductive bias that improves learning\n",
    "on image-based data.\n",
    "\n",
    "Using the Fashion-MNIST dataset, we compare a baseline fully connected network against a\n",
    "convolutional neural network (CNN), and perform controlled experiments to analyze the effect\n",
    "of convolutional design choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dcd5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed Fashion-MNIST CSV files\n",
    "train_df = pd.read_csv(\"data/processed/fashion-mnist-train.csv\")\n",
    "test_df  = pd.read_csv(\"data/processed/fashion-mnist-test.csv\")\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c0ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "train_df[\"label\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cfba2a",
   "metadata": {},
   "source": [
    "- Each sample contains 784 numerical pixel values (28×28 image)\n",
    "- Labels range from 0 to 9 (10 clothing categories)\n",
    "- Images are grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7157dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(df, n=6):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    for i in range(n):\n",
    "        pixels = df.iloc[i, 1:].values.reshape(28, 28)\n",
    "        label = df.iloc[i, 0]\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(pixels, cmap=\"gray\")\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea5c48c",
   "metadata": {},
   "source": [
    "Preprocessing steps:\n",
    "- Normalize pixel values to [0, 1]\n",
    "- Reshape data for CNN input\n",
    "- Convert labels to tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.iloc[:, 1:].values / 255.0\n",
    "y_train = train_df.iloc[:, 0].values\n",
    "\n",
    "X_test = test_df.iloc[:, 1:].values / 255.0\n",
    "y_test = test_df.iloc[:, 0].values\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890cc53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx].reshape(1, 28, 28)  # 1 channel\n",
    "        label = self.y[idx]\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6db501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionMNISTDataset(X_train, y_train)\n",
    "test_dataset  = FashionMNISTDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773f0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = BaselineNN()\n",
    "sum(p.numel() for p in baseline_model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04678c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, epochs=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x, y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(x)\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        history.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf78c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_history = train_model(baseline_model, train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70503893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = FashionMNISTCNN()\n",
    "sum(p.numel() for p in cnn_model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_history = train_model(cnn_model, train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa134e5",
   "metadata": {},
   "source": [
    "Experiment:\n",
    "- Compare kernel size 3×3 vs 5×5\n",
    "- Keep all other parameters fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24aaa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNKernel5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 14 * 14, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87465454",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_k5 = CNNKernel5()\n",
    "train_model(cnn_k5, train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e383962c",
   "metadata": {},
   "source": [
    "### Why did convolutional layers outperform the baseline?\n",
    "Convolutional layers exploit spatial locality and weight sharing, reducing the number of parameters\n",
    "while preserving spatial structure.\n",
    "\n",
    "### What inductive bias does convolution introduce?\n",
    "Translation invariance and local feature extraction.\n",
    "\n",
    "### When is convolution not appropriate?\n",
    "For non-spatial data such as tabular business metrics or symbolic data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47998bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained CNN model\n",
    "torch.save(cnn_model.state_dict(), \"model.pth\")\n",
    "print(\"Model saved as model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f31dfb",
   "metadata": {},
   "source": [
    "This experiment demonstrates that convolutional layers are not merely performance optimizations,\n",
    "but architectural components that encode domain assumptions.\n",
    "\n",
    "Understanding these assumptions is critical for designing robust and explainable AI systems\n",
    "in enterprise environments.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
